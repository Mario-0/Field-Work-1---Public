{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BootMR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\BootMR\\Documents\\data_export\n"
     ]
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import flirt\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Specify the path to the desired directory\n",
    "parent_dir = r'<<< PLACE HERE DIRECTORY WITH DATASET >>>'\n",
    "\n",
    "# Change the current working directory to the specified directory\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "mastertimesheet = pd.read_excel(\"mastertimesheet-4.xlsx\")\n",
    "\n",
    "# Add leading zero to p_id values below 10\n",
    "mastertimesheet['p_id'] = mastertimesheet['p_id'].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "# Verify that the working directory has been changed\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Function to load file into a DataFrame\n",
    "def load_file_into_dataframe(folder_path, var, filetype, sep=','):\n",
    "    var_files = [f for f in os.listdir(folder_path) if f.endswith(filetype) and var in f]\n",
    "    \n",
    "    if var_files:\n",
    "        file_path = os.path.join(folder_path, var_files[0])\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep)\n",
    "            print(f\"Loaded file: {file_path}\")\n",
    "            return df\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"The file {file_path} is empty.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while reading the file {file_path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No file with '{var}' in its name found in folder {folder_path}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for all participants per 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features: 100%|██████████| 3689/3689 [00:48<00:00, 76.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDA features: 100%|██████████| 5250/5250 [00:20<00:00, 251.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\3612163382.py:66: UserWarning: tonic_entropy contains more than 5% (actual: 28.95%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_30s = flirt.with_.empatica(zip_file_path,\n",
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\3612163382.py:66: UserWarning: phasic_entropy contains more than 5% (actual: 45.03%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_30s = flirt.with_.empatica(zip_file_path,\n",
      "ACC features: 100%|██████████| 5252/5252 [00:24<00:00, 210.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n",
      "Features saved to C:\\Users\\BootMR\\Documents\\data_export\\03\\features_30s_03_1716369725_a02601.zip.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features: 100%|██████████| 4624/4624 [00:01<00:00, 3211.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDA features: 100%|██████████| 5043/5043 [00:23<00:00, 218.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\3612163382.py:66: UserWarning: phasic_entropy contains more than 5% (actual: 54.95%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_30s = flirt.with_.empatica(zip_file_path,\n",
      "ACC features: 100%|██████████| 5045/5045 [00:28<00:00, 177.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n",
      "Features saved to C:\\Users\\BootMR\\Documents\\data_export\\04\\features_30s_04_1714996826_a02601.zip.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Simple Summary of What the Script Does:\n",
    "\n",
    "    Clean and Prepare Data:\n",
    "        Remove bad columns: The clean_features() function is designed to remove any columns in the DataFrame that have too many missing values (more than 5%) or contain infinite values.\n",
    "        Ensure numeric data: The ensure_numeric() function converts all columns to numeric types, forcing any non-numeric values (like strings) to become NaN (missing data).\n",
    "\n",
    "    Process Each Subfolder:\n",
    "        The script looks through a parent directory and processes each subfolder one by one.\n",
    "        For each subfolder, it checks if the folder contains a .zip file.\n",
    "\n",
    "    Extract Features from the Zip File:\n",
    "        If a zip file is found in the subfolder, the script uses a tool (probably flirt.with_empatica) to compute features from the zip file. These features could include:\n",
    "            HRV (Heart Rate Variability) features\n",
    "            EDA (Electrodermal Activity) features\n",
    "            Accelerometer (ACC) features\n",
    "        The features are computed using windows of 30 seconds with a step size of 1 second between windows.\n",
    "\n",
    "    Clean and Save Data:\n",
    "        The script ensures that all features are numeric (using ensure_numeric()).\n",
    "        It then saves the computed features to a CSV file in the same subfolder where the zip file was located, with a filename based on the subfolder name and zip file name.\n",
    "\n",
    "    Error Handling:\n",
    "        If anything goes wrong while processing a zip file, it catches the error and prints a message without crashing the entire script.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "    The script processes zip files in subfolders, extracts time-based features (HRV, EDA, ACC), cleans the data, ensures it's numeric, and saves the results to CSV files.\n",
    "\n",
    "'''\n",
    "\n",
    "# Function to clean the DataFrame\n",
    "def clean_features(df):\n",
    "    threshold = 0.05  # 5% threshold\n",
    "    columns_to_remove = [col for col in df.columns if df[col].isna().mean() > threshold or df[col].isin([float('inf'), float('-inf')]).mean() > threshold]\n",
    "    if columns_to_remove:\n",
    "        print(f\"Removing columns due to high NaN/Inf values: {columns_to_remove}\")\n",
    "        df = df.drop(columns=columns_to_remove)\n",
    "    return df\n",
    "\n",
    "# Function to check and convert data to numeric\n",
    "def ensure_numeric(data):\n",
    "    for col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    return data\n",
    "\n",
    "# Iterate over each subfolder in the parent directory\n",
    "for subfolder_name in os.listdir(parent_dir):\n",
    "\n",
    "    subfolder_path = os.path.join(parent_dir, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Find the zip file in the subfolder\n",
    "        zip_file = None\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            if file_name.endswith('.zip'):\n",
    "                zip_file = file_name\n",
    "                break\n",
    "        \n",
    "        if zip_file:\n",
    "            zip_file_path = os.path.join(subfolder_path, zip_file)\n",
    "            \n",
    "            try:\n",
    "                # Compute features using flirt.with_empatica\n",
    "                features_30s = flirt.with_.empatica(zip_file_path,\n",
    "                                                   window_length=30,\n",
    "                                                   window_step_size=1,\n",
    "                                                   hrv_features=True,\n",
    "                                                   eda_features=True,\n",
    "                                                   acc_features=True)\n",
    "                \n",
    "                # Clean the DataFrame\n",
    "                #features_30s = clean_features(features_30s)\n",
    "                \n",
    "                # Ensure all data is numeric\n",
    "                features_30s = ensure_numeric(features_30s)\n",
    "                \n",
    "                # Define the file path where you want to save the CSV file\n",
    "                output_csv_path = os.path.join(subfolder_path, f'features_30s_{subfolder_name}_{zip_file}.csv')\n",
    "                \n",
    "                # Write the DataFrame to a CSV file\n",
    "                features_30s.to_csv(output_csv_path, index=True)\n",
    "                print(f'Features saved to {output_csv_path}')\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {zip_file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline calc 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BootMR\\Documents\\data_export\\00-code_export\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features:   0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features: 100%|██████████| 61/61 [00:00<00:00, 752.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDA features: 100%|██████████| 88/88 [00:00<00:00, 174.43it/s]\n",
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\2229191125.py:53: UserWarning: tonic_entropy contains more than 5% (actual: 31.82%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_60s = flirt.with_.empatica(zip_file_path,\n",
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\2229191125.py:53: UserWarning: phasic_entropy contains more than 5% (actual: 44.32%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_60s = flirt.with_.empatica(zip_file_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACC features: 100%|██████████| 88/88 [00:00<00:00, 128.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n",
      "Features saved to C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_FlirtFeatures.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features: 100%|██████████| 77/77 [00:00<00:00, 936.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EDA features: 100%|██████████| 85/85 [00:00<00:00, 123.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BootMR\\AppData\\Local\\Temp\\ipykernel_25716\\2229191125.py:53: UserWarning: phasic_entropy contains more than 5% (actual: 56.47%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  features_60s = flirt.with_.empatica(zip_file_path,\n",
      "ACC features: 100%|██████████| 85/85 [00:01<00:00, 64.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n",
      "Features saved to C:\\Users\\BootMR\\Documents\\data_export\\04\\04_baseline_FlirtFeatures.csv\n"
     ]
    }
   ],
   "source": [
    "### start with computing features per minute\n",
    "\n",
    "'''\n",
    "\n",
    "Simple Summary of What the Script Does:\n",
    "\n",
    "    Clean and Prepare Data:\n",
    "        Remove bad columns: The clean_features() function is designed to remove any columns in the DataFrame that have too many missing values (more than 5%) or contain infinite values.\n",
    "        Ensure numeric data: The ensure_numeric() function converts all columns to numeric types, forcing any non-numeric values (like strings) to become NaN (missing data).\n",
    "\n",
    "    Process Each Subfolder:\n",
    "        The script looks through a parent directory and processes each subfolder one by one.\n",
    "        For each subfolder, it checks if the folder contains a .zip file.\n",
    "\n",
    "    Extract Features from the Zip File:\n",
    "        If a zip file is found in the subfolder, the script uses a tool (probably flirt.with_empatica) to compute features from the zip file. These features could include:\n",
    "            HRV (Heart Rate Variability) features\n",
    "            EDA (Electrodermal Activity) features\n",
    "            Accelerometer (ACC) features\n",
    "        The features are computed using windows of 30 seconds with a step size of 1 second between windows.\n",
    "\n",
    "    Clean and Save Data:\n",
    "        The script ensures that all features are numeric (using ensure_numeric()).\n",
    "        It then saves the computed features to a CSV file in the same subfolder where the zip file was located, with a filename based on the subfolder name and zip file name.\n",
    "\n",
    "    Error Handling:\n",
    "        If anything goes wrong while processing a zip file, it catches the error and prints a message without crashing the entire script.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "    The script processes zip files in subfolders, extracts time-based features (HRV, EDA, ACC), cleans the data, ensures it's numeric, and saves the results to CSV files.\n",
    "\n",
    "'''\n",
    "\n",
    "# Iterate over each subfolder in the parent directory\n",
    "for subfolder_name in os.listdir(parent_dir):\n",
    "    subfolder_path = os.path.join(parent_dir, subfolder_name)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(subfolder_path)\n",
    "        # Find the zip file in the subfolder\n",
    "        zip_file = None\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            if file_name.endswith('.zip'):\n",
    "                zip_file = file_name\n",
    "                break\n",
    "        \n",
    "        if zip_file:\n",
    "            zip_file_path = os.path.join(subfolder_path, zip_file)\n",
    "            \n",
    "            try:\n",
    "                # Compute features using flirt.with_empatica\n",
    "                features_60s = flirt.with_.empatica(zip_file_path,\n",
    "                                                   window_length=60,\n",
    "                                                   window_step_size=60,\n",
    "                                                   hrv_features=True,\n",
    "                                                   eda_features=True,\n",
    "                                                   acc_features=True)\n",
    "                \n",
    "                # Clean the DataFrame\n",
    "                #features_60s = clean_features(features_60s)\n",
    "                \n",
    "                # Ensure all data is numeric\n",
    "                features_60s = ensure_numeric(features_60s)\n",
    "                \n",
    "                # Write the DataFrame to a CSV file\n",
    "                output_csv_path = os.path.join(subfolder_path, f'{subfolder_name}_baseline_FlirtFeatures.csv')\n",
    "                features_60s.to_csv(output_csv_path, index=True)\n",
    "                print(f'Features saved to {output_csv_path}')\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {zip_file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline calc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-code_export\n",
      "No file with 'baseline_FlirtFeatures' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "baseline_FlirtFeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_FlirtFeatures.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_FlirtFeatures_means.csv successfully SAVED for 03\n",
      "04\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\04\\04_baseline_FlirtFeatures.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\04\\04_baseline_FlirtFeatures_means.csv successfully SAVED for 04\n",
      "all_baseline_FlirtFeatures_means.csv\n",
      "all_ratingswHRV.csv\n",
      "mastertimesheet-4.xlsx\n",
      "responses-full-cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "# worked well 30th Jan. computes baseline descriptive stats and HRV features for all pids\n",
    "#succesfully svaed 46 baseline files\n",
    "\n",
    "\n",
    "skip_p_ids = [f\"{i:02}\" for i in range(1)]\n",
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "\n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "\n",
    "    print(p_id)\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "\n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        baseline_FlirtFeatures = load_file_into_dataframe(folder_path, 'baseline_FlirtFeatures', '.csv', ',')\n",
    "\n",
    "        if baseline_FlirtFeatures is None:\n",
    "            print(f\"baseline_FlirtFeatures missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "\n",
    "        baseline_FlirtFeatures.rename(columns={baseline_FlirtFeatures.columns[0]: 'timestamp'}, inplace=True)\n",
    "        baseline_FlirtFeatures['timestamp'] = pd.to_datetime(baseline_FlirtFeatures['timestamp']).dt.tz_localize(None)\n",
    "        baseline_FlirtFeatures['timestamp'] = pd.to_datetime(baseline_FlirtFeatures['timestamp'])\n",
    "        baseline_FlirtFeatures['timestamp'] += pd.Timedelta(hours=2)\n",
    "\n",
    "        if baseline_FlirtFeatures is not None:\n",
    "            # Convert 'timestamp' columns to datetime format\n",
    "            baseline_FlirtFeatures['timestamp'] = pd.to_datetime(baseline_FlirtFeatures['timestamp'])\n",
    "\n",
    "            ######### select baseline data by timestamps\n",
    "\n",
    "            mask = mastertimesheet['p_id'] == p_id\n",
    "            if mask.any():\n",
    "                idx = mastertimesheet.index[mask][0]\n",
    "                # Check if both start and end times are present in the mastertimesheet\n",
    "                startt0 = mastertimesheet.loc[idx, 'startt0']\n",
    "                startt1 = mastertimesheet.loc[idx, 'startt1']\n",
    "                \n",
    "                if pd.isna(startt0) or pd.isna(startt1):\n",
    "                    print(f\"Missing start or end time for p_id {p_id}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Set start and end time based on startt0 and startt1\n",
    "                start_time = pd.to_datetime(startt0)\n",
    "                end_time = pd.to_datetime(startt1)\n",
    "            else:\n",
    "                print(f\"No matching entry found in mastertimesheet for p_id {p_id}\")\n",
    "                continue\n",
    "\n",
    "            # Filter DataFrames based on the time range\n",
    "\n",
    "            filtered_baseline = baseline_FlirtFeatures[(baseline_FlirtFeatures['timestamp'] >= start_time) & (baseline_FlirtFeatures['timestamp'] <= end_time)]\n",
    "\n",
    "            averages = filtered_baseline.mean()\n",
    "\n",
    "            # Convert the Series to a DataFrame and rename it\n",
    "            flirt_baseline = pd.DataFrame(averages).T  # Transpose to keep column headers\n",
    "\n",
    "            # Display the new dataframe\n",
    "            #print(flirt_baseline)\n",
    "        \n",
    "            # Save the results to a CSV file named after the p_id\n",
    "            output_file_path = os.path.join(folder_path, f\"{p_id}_baseline_FlirtFeatures_means.csv\")\n",
    "            flirt_baseline.to_csv(output_file_path, index=None)\n",
    "            print(f\"{output_file_path} successfully SAVED for {p_id}\")\n",
    "        else:\n",
    "            print(f\"Skipping folder {folder_path} due to missing data files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\00-code_export\n",
      "No file with 'baseline_FlirtFeatures_means' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "No file with 'features_30s' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "baseline_Flirtfeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_FlirtFeatures_means.csv\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\features_30s_03_1716369725_a02601.zip.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\\03_flirtFeatures_30s_baselinecorrected.csv successfully saved for 03\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\04\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\04\\04_baseline_FlirtFeatures_means.csv\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\04\\features_30s_04_1714996826_a02601.zip.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\04\\04_flirtFeatures_30s_baselinecorrected.csv successfully saved for 04\n"
     ]
    }
   ],
   "source": [
    "## worked well 3rd Feb\n",
    "\n",
    "skip_p_ids = [f\"{i:02}\" for i in range(1)]\n",
    "\n",
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "    \n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        \n",
    "        print(f\"Processing folder: {folder_path}\")\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        baseline_FlirtFeatures_means = load_file_into_dataframe(folder_path, 'baseline_FlirtFeatures_means', '.csv', ',')      \n",
    "        flirtFeatures_30s = load_file_into_dataframe(folder_path, 'features_30s', '.csv', ',')\n",
    "\n",
    "        if baseline_FlirtFeatures_means is None or baseline_FlirtFeatures_means.empty:\n",
    "            print(f\"baseline_Flirtfeatures missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if flirtFeatures_30s is None or flirtFeatures_30s.empty:\n",
    "            print(f\"flirtFeatures_30s missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "\n",
    "        # give header to 1st col\n",
    "\n",
    "        baseline_FlirtFeatures_means.rename(columns={baseline_FlirtFeatures_means.columns[0]: 'timestamp'}, inplace=True)\n",
    "        baseline_FlirtFeatures_means['timestamp'] = pd.to_datetime(baseline_FlirtFeatures_means['timestamp']).dt.tz_localize(None)\n",
    "\n",
    "        flirtFeatures_30s.rename(columns={flirtFeatures_30s.columns[0]: 'timestamp'}, inplace=True)\n",
    "        flirtFeatures_30s['timestamp'] = pd.to_datetime(flirtFeatures_30s['timestamp']).dt.tz_localize(None)\n",
    "        \n",
    "        if baseline_FlirtFeatures_means is not None and flirtFeatures_30s is not None:\n",
    "\n",
    "            # Ensure all columns in baseline_Flirtfeatures exist in flirtFeatures_30s\n",
    "            for col in baseline_FlirtFeatures_means.columns:\n",
    "                if col not in flirtFeatures_30s.columns:\n",
    "                    flirtFeatures_30s[col] = float('nan')  # Fill missing columns with Nans\n",
    "\n",
    "            # Ignore the timestamp column (assumed to be the first column)\n",
    "            flirt_columns = baseline_FlirtFeatures_means.columns[1:]\n",
    "\n",
    "            # Convert baseline features to a NumPy array and subtract it row-wise\n",
    "            baseline_values = baseline_FlirtFeatures_means.iloc[0, 1:].values  # Extract numeric row as array\n",
    "\n",
    "            flirtFeatures_30s.loc[:, flirt_columns] = flirtFeatures_30s.loc[:, flirt_columns] - baseline_values\n",
    "\n",
    "            # Z-standardize each HRV feature\n",
    "            #flirtFeatures_30s[flirt_columns] = (flirtFeatures_30s[flirt_columns] - flirtFeatures_30s[flirt_columns].mean()) / flirtFeatures_30s[flirt_columns].std()\n",
    "\n",
    "            # Save the concatenated DataFrame to CSV\n",
    "            output_file_path = os.path.join(folder_path, f\"{p_id}_flirtFeatures_30s_baselinecorrected.csv\")\n",
    "            flirtFeatures_30s.to_csv(output_file_path, index=None)\n",
    "            print(f\"{output_file_path} successfully saved for {p_id}\")\n",
    "        else:\n",
    "            print(f\"Skipping folder {folder_path} due to missing data files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge baselines into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\BootMR\\Documents\\data_export\\all_baseline_FlirtFeatures_means.csv\n",
      "Processing file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_FlirtFeatures_means.csv\n",
      "Processing file: C:\\Users\\BootMR\\Documents\\data_export\\04\\04_baseline_FlirtFeatures_means.csv\n",
      "All files merged into: C:\\Users\\BootMR\\Documents\\data_export\\all_baseline_FlirtFeatures_means.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate through each subfolder in the parent directory\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    # Check each file in the subfolder\n",
    "    for file in files:\n",
    "        if 'baseline_FlirtFeatures_means' in file:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "if dfs:\n",
    "    all_baseline_HRVfeatures = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(parent_dir, 'all_baseline_FlirtFeatures_means.csv')\n",
    "    \n",
    "    # Save the concatenated DataFrame to CSV\n",
    "    all_baseline_HRVfeatures.to_csv(output_file_path, index=False)\n",
    "    print(f\"All files merged into: {output_file_path}\")\n",
    "else:\n",
    "    print(\"No files found with 'baseline_HRVfeatures' in the filename.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

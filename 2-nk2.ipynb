{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\BootMR\\Documents\\data_export\n"
     ]
    }
   ],
   "source": [
    "import neurokit2 as nk\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Specify the path to the desired directory\n",
    "parent_dir = r'<<< PLACE HERE DIRECTORY WITH DATASET >>>'\n",
    "\n",
    "# Change the current working directory to the specified directory\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "mastertimesheet = pd.read_excel(\"mastertimesheet-4.xlsx\")\n",
    "\n",
    "# Add leading zero to p_id values below 10\n",
    "mastertimesheet['p_id'] = mastertimesheet['p_id'].apply(lambda x: str(x).zfill(2))\n",
    "\n",
    "# Verify that the working directory has been changed\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Function to load file into a DataFrame\n",
    "def load_file_into_dataframe(folder_path, var, filetype, sep=','):\n",
    "    var_files = [f for f in os.listdir(folder_path) if f.endswith(filetype) and var in f]\n",
    "    \n",
    "    if var_files:\n",
    "        file_path = os.path.join(folder_path, var_files[0])\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep)\n",
    "            print(f\"Loaded file: {file_path}\")\n",
    "            return df\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"The file {file_path} is empty.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while reading the file {file_path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No file with '{var}' in its name found in folder {folder_path}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc features all pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"neurokit2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\00-code_export\n",
      "No file with '_ecg' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "No file with 'buttons_gps.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "ECG file is missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\polar_h10_cbd9da26_20240522_111821_ecg.txt\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_buttons_gps.csv\n",
      "start nk.ecg_process for timestamp 2024-05-22 11:43:04.127494\n",
      "start nk.hrv for timestamp 2024-05-22 11:43:04.127494\n",
      "start nk.ecg_process for timestamp 2024-05-22 11:47:22.196925\n",
      "start nk.hrv for timestamp 2024-05-22 11:47:22.196925\n",
      "start nk.ecg_process for timestamp 2024-05-22 11:50:47.987902\n",
      "start nk.hrv for timestamp 2024-05-22 11:50:47.987902\n",
      "start nk.ecg_process for timestamp 2024-05-22 12:06:18.554372\n",
      "start nk.hrv for timestamp 2024-05-22 12:06:18.554372\n",
      "start nk.ecg_process for timestamp 2024-05-22 12:07:35.941486\n",
      "start nk.hrv for timestamp 2024-05-22 12:07:35.941486\n",
      "start nk.ecg_process for timestamp 2024-05-22 12:07:38.644613\n",
      "start nk.hrv for timestamp 2024-05-22 12:07:38.644613\n",
      "start nk.ecg_process for timestamp 2024-05-22 12:27:01.459779\n",
      "start nk.hrv for timestamp 2024-05-22 12:27:01.459779\n",
      "start nk.ecg_process for timestamp 2024-05-22 12:28:42.473445\n",
      "start nk.hrv for timestamp 2024-05-22 12:28:42.473445\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratingsECGfeatures.csv successfully saved for 03\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\04\n",
      "No file with '_ecg' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\04\\04_buttons_gps.csv\n",
      "ECG file is missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### worked well 28th Jan\n",
    "#(original)\n",
    "\n",
    "''' Explanation: \n",
    "\n",
    "Here's a simplified explanation of what the script does:\n",
    "\n",
    "    Window Definition:\n",
    "        The script defines a time window of 30 seconds, 15 seconds before and 15 seconds after a button press.\n",
    "\n",
    "    Folder Setup:\n",
    "        The script looks at a root folder (root_folder_path) containing subfolders, each corresponding to a participant (p_id).\n",
    "        It skips any participant IDs listed in skip_p_ids.\n",
    "\n",
    "    Loading Files:\n",
    "        The script has a function that loads files into pandas DataFrames based on a variable name (e.g., ECG or buttons data).\n",
    "        It looks for files ending in .txt for ECG and .csv for button press data.\n",
    "\n",
    "    Data Processing:\n",
    "        For each participant folder:\n",
    "            It tries to load two types of data: ECG data and button press data.\n",
    "            If either data file is missing or empty, it skips the folder.\n",
    "            If both data files are present, it processes the ECG data based on the button press timestamps.\n",
    "\n",
    "    Button Press Window:\n",
    "        For each button press:\n",
    "            It filters the ECG data to the 30-second window (15 seconds before and after the button press).\n",
    "            It then processes the ECG signals using neurokit2 to calculate heart rate variability (HRV) metrics.\n",
    "\n",
    "    Saving Results:\n",
    "        The script stores the HRV features for each button press in a DataFrame, along with the button press timestamp and rating.\n",
    "        It saves the results in a CSV file named after the participant.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "    Purpose: The script processes ECG data around button press events to extract heart rate variability (HRV) features.\n",
    "    Files Processed: For each participant, it loads ECG data and button press data, processes them, and saves the results in a new CSV file.\n",
    "    HRV Calculation: Uses neurokit2 for ECG processing and HRV feature extraction.\n",
    "\n",
    "'''\n",
    "\n",
    "# Define window length in seconds around button press, currently equal before and after\n",
    "window_length = 30\n",
    "interval_before = window_length / 2\n",
    "interval_after = window_length / 2\n",
    "\n",
    "# List of p_ids to skip\n",
    "#skip_p_ids = []  # Add any p_ids you want to skip\n",
    "skip_p_ids = [f\"{i:02}\" for i in range(1)]\n",
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "    \n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        \n",
    "        print(f\"Processing folder: {folder_path}\")\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        ecg = load_file_into_dataframe(folder_path, '_ecg', '.txt', ';')\n",
    "        buttons = load_file_into_dataframe(folder_path, 'buttons_gps.csv', '.csv', ',')\n",
    "        \n",
    "        if ecg is None or ecg.empty:\n",
    "            print(f\"ECG file is missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if buttons is None or buttons.empty:\n",
    "            print(f\"Buttons file is missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if ecg is not None and buttons is not None and ecg is not None:\n",
    "            # Convert 'timestamp' columns to datetime format\n",
    "            ecg['Phone timestamp'] = pd.to_datetime(ecg['Phone timestamp'])\n",
    "            buttons['timestamp_button'] = pd.to_datetime(buttons['timestamp_button'])\n",
    "                        \n",
    "            # Iterate through each timestamp in buttons\n",
    "            for index, row in buttons.iterrows():\n",
    "                timestamp = row['timestamp_button']\n",
    "                rating = row['rating']\n",
    "\n",
    "                ######### filter on timestamp\n",
    "                                \n",
    "                # Define the time range for filtering (15 seconds before and after the timestamp)\n",
    "                start_time = timestamp - pd.Timedelta(seconds=interval_before)\n",
    "                end_time = timestamp + pd.Timedelta(seconds=interval_after)\n",
    "                \n",
    "                # Filter on the time range\n",
    "                filtered_ecg = ecg[(ecg['Phone timestamp'] >= start_time) & (ecg['Phone timestamp'] <= end_time)]\n",
    "\n",
    "                ######### HRV feature calculation with neurokit\n",
    "                \n",
    "                # Extract ECG data for processing\n",
    "                filtered_ecg_ecgonly = filtered_ecg['ecg [uV]']\n",
    "                \n",
    "                # Process raw ECG data into QRS metrics\n",
    "                print(f'start nk.ecg_process for timestamp {timestamp}')\n",
    "                filtered_ecg_ecgonly_signals, _ = nk.ecg_process(filtered_ecg_ecgonly, sampling_rate=130, method='neurokit')\n",
    "                \n",
    "                # Calculate HRV features\n",
    "                print(f'start nk.hrv for timestamp {timestamp}')\n",
    "                hrv_features = nk.hrv(filtered_ecg_ecgonly_signals['ECG_R_Peaks'], sampling_rate=130, nperseg=256, show=False)\n",
    "                \n",
    "                # Insert 'timestamp' and 'rating' as the first columns in hrv_features DataFrame\n",
    "                hrv_features.insert(0, 'button_timestamp', timestamp)\n",
    "                hrv_features.insert(1, 'rating', rating)\n",
    "                hrv_features.insert(2, 'window_start_time', start_time)\n",
    "                hrv_features.insert(3, 'window_end_time', end_time)\n",
    "                \n",
    "                button_features = pd.concat([button_features, hrv_features], ignore_index=True)\n",
    "\n",
    "            # Merge buttons and button_features on 'timestamp_button'\n",
    "            merged_features = pd.merge(buttons, button_features, how='left', left_on='timestamp_button', right_on='button_timestamp')\n",
    "\n",
    "            merged_features.drop(columns=['button_timestamp','rating_y'], inplace=True)\n",
    "            merged_features.rename(columns={'rating_x': 'rating'}, inplace=True)\n",
    "            first_column = merged_features.pop('rating')\n",
    "            merged_features.insert(0, 'rating', first_column)\n",
    " \n",
    "            # Save the concatenated DataFrame to CSV\n",
    "            output_file_path = os.path.join(folder_path, f\"{p_id}_ratingsECGfeatures.csv\")\n",
    "            merged_features.to_csv(output_file_path, index=None)\n",
    "            print(f\"{output_file_path} successfully saved for {p_id}\")\n",
    "        else:\n",
    "            print(f\"Skipping folder {folder_path} due to missing data files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-code_export\n",
      "No file with 'ratingsECGfeatures.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "No file with '_hr' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "ratingsECGfeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratingsECGfeatures.csv\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\polar_h10_cbd9da26_20240522_111820_hr.txt\n",
      "Saved C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratings_wHRV.csv\n",
      "04\n",
      "No file with 'ratingsECGfeatures.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "No file with '_hr' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "ratingsECGfeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "    \n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        \n",
    "        print(p_id)\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        ratingsECGfeatures = load_file_into_dataframe(folder_path, 'ratingsECGfeatures.csv', '.csv', ',')\n",
    "        hr = load_file_into_dataframe(folder_path, '_hr', '.txt', ';')\n",
    "        \n",
    "        if ratingsECGfeatures is None or ratingsECGfeatures.empty:\n",
    "            print(f\"ratingsECGfeatures missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if hr is None or hr.empty:\n",
    "            print(f\"hr missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if ratingsECGfeatures is not None and hr is not None:\n",
    "            # Convert 'timestamp' columns to datetime format\n",
    "            hr['Phone timestamp'] = pd.to_datetime(hr['Phone timestamp'])\n",
    "            ratingsECGfeatures['timestamp_button'] = pd.to_datetime(ratingsECGfeatures['timestamp_button'])\n",
    "                        \n",
    "            # Iterate through each timestamp in ratingsECGfeatures\n",
    "            for index, row in ratingsECGfeatures.iterrows():\n",
    "                timestamp = row['timestamp_button']\n",
    "                rating = row['rating']\n",
    "\n",
    "                ######### filter on timestamp\n",
    "                                \n",
    "                # Define the time range for filtering (15 seconds before and after the timestamp)\n",
    "                start_time = row['window_start_time']\n",
    "                end_time = row['window_end_time']\n",
    "                \n",
    "                # Filter on the time range\n",
    "                filtered_hr = hr[(hr['Phone timestamp'] >= start_time) & (hr['Phone timestamp'] <= end_time)]\n",
    "                \n",
    "                ######### Descriptive statistic calculation\n",
    "\n",
    "                # Compute descriptive statistics for HR [bpm] and HRV [ms]\n",
    "                hr_column = 'HR [bpm]'\n",
    "                hrv_column = 'HRV [ms]'\n",
    "                            \n",
    "                hr_mean = round(filtered_hr[hr_column].mean(), 2)\n",
    "                hr_stdev = round(filtered_hr[hr_column].std(), 2)\n",
    "                hrv_mean = round(filtered_hr[hrv_column].mean(), 2)\n",
    "                hrv_stdev = round(filtered_hr[hrv_column].std(), 2)\n",
    "\n",
    "                # Create a dictionary with the results\n",
    "                stats = {\n",
    "                    'hr_mean': hr_mean,\n",
    "                    'hr_stdev': hr_stdev,\n",
    "                    'hrv_mean': hrv_mean,\n",
    "                    'hrv_stdev': hrv_stdev\n",
    "                }\n",
    "\n",
    "                # Add the stats as new columns to the ratingsECGfeatures row\n",
    "                for stat_name, stat_value in stats.items():\n",
    "                    ratingsECGfeatures.loc[index, stat_name] = stat_value\n",
    "\n",
    "            ######### Reorder the columns: Place new stats columns after 'window_end_time'\n",
    "            # Get the columns order\n",
    "            column_order = list(ratingsECGfeatures.columns)\n",
    "\n",
    "            # Find the index of 'window_end_time' and insert the stats columns after it\n",
    "            window_end_time_index = column_order.index('window_end_time')\n",
    "\n",
    "            # Reorder columns to place the new stats in the desired location\n",
    "            new_column_order = (\n",
    "                column_order[:window_end_time_index + 1] + \n",
    "                ['hr_mean', 'hr_stdev', 'hrv_mean', 'hrv_stdev'] + \n",
    "                column_order[window_end_time_index + 1:]\n",
    "            )\n",
    "            \n",
    "            ratingsECGfeatures = ratingsECGfeatures[new_column_order]\n",
    "\n",
    "        # Optionally save the updated DataFrame\n",
    "        output_file_path = os.path.join(folder_path, f\"{p_id}_ratings_wHRV.csv\")\n",
    "        ratingsECGfeatures.to_csv(output_file_path, index=False)\n",
    "        print(f\"Saved {output_file_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc baseline all pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00-code_export\n",
      "No file with '_ecg' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "No file with '_hr' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "ECG file is missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "Skipping folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export due to missing data files.\n",
      "03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\polar_h10_cbd9da26_20240522_111821_ecg.txt\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\polar_h10_cbd9da26_20240522_111820_hr.txt\n",
      "start nk.hrv for 2024-05-22 11:28:00 until 2024-05-22 11:42:00\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_HRVfeatures.csv successfully SAVED for 03\n",
      "04\n",
      "No file with '_ecg' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "No file with '_hr' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "ECG file is missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "Skipping folder C:\\Users\\BootMR\\Documents\\data_export\\04 due to missing data files.\n",
      "all_baseline_FlirtFeatures_means.csv\n",
      "all_ratingswHRV.csv\n",
      "mastertimesheet-4.xlsx\n",
      "responses-full-cleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "# worked well 30th Jan. computes baseline descriptive stats and HRV features for all pids\n",
    "#succesfully svaed 46 baseline files\n",
    "\n",
    "\n",
    "skip_p_ids = [f\"{i:02}\" for i in range(1)]\n",
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "\n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "\n",
    "    print(p_id)\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "\n",
    "    output_file_path = os.path.join(folder_path, f\"{p_id}_baseline_HRVfeatures.csv\")\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Check if the output file already exists; if so, skip processing\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f\"File {p_id}_baseline_ECGfeatures.csv already exists. Skipping folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        ecg = load_file_into_dataframe(folder_path, '_ecg', '.txt', ';')\n",
    "        hr = load_file_into_dataframe(folder_path, '_hr', '.txt', ';')\n",
    "\n",
    "        if ecg is None:\n",
    "            print(f\"ECG file is missing or empty in folder {folder_path}.\")\n",
    "\n",
    "        if ecg is not None:\n",
    "            # Convert 'timestamp' columns to datetime format\n",
    "            ecg['Phone timestamp'] = pd.to_datetime(ecg['Phone timestamp'])\n",
    "            hr['Phone timestamp'] = pd.to_datetime(hr['Phone timestamp'])\n",
    "\n",
    "            ######### select baseline data by timestamps\n",
    "\n",
    "            mask = mastertimesheet['p_id'] == p_id\n",
    "            if mask.any():\n",
    "                idx = mastertimesheet.index[mask][0]\n",
    "                # Check if both start and end times are present in the mastertimesheet\n",
    "                startt0 = mastertimesheet.loc[idx, 'startt0']\n",
    "                startt1 = mastertimesheet.loc[idx, 'startt1']\n",
    "                \n",
    "                if pd.isna(startt0) or pd.isna(startt1):\n",
    "                    print(f\"Missing start or end time for p_id {p_id}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Set start and end time based on startt0 and startt1\n",
    "                start_time = pd.to_datetime(startt0)\n",
    "                end_time = pd.to_datetime(startt1)\n",
    "            else:\n",
    "                print(f\"No matching entry found in mastertimesheet for p_id {p_id}\")\n",
    "                continue\n",
    "\n",
    "            # Filter DataFrames based on the time range\n",
    "            # Filter ecg DataFrame based on the time range\n",
    "            filtered_hr = hr[(hr['Phone timestamp'] >= start_time) & (hr['Phone timestamp'] <= end_time)]\n",
    "            filtered_ecg = ecg[(ecg['Phone timestamp'] >= start_time) & (ecg['Phone timestamp'] <= end_time)]\n",
    "\n",
    "            # Check if there is any data in the filtered_ecg DataFrame\n",
    "            if filtered_ecg.empty:\n",
    "                print(f\"No ECG data found between {start_time} and {end_time}. Skipping {p_id}.\")\n",
    "                continue\n",
    "\n",
    "            # Check if there is any data in the filtered_hr DataFrame\n",
    "            if filtered_hr.empty:\n",
    "                print(f\"No hr data found between {start_time} and {end_time}. Skipping {p_id}.\")\n",
    "                continue\n",
    "            \n",
    "            ######### HRV feature calculation with neurokit\n",
    "\n",
    "            # Extract ECG data for processing\n",
    "            filtered_ecg_ecgonly = filtered_ecg['ecg [uV]']\n",
    "            \n",
    "            # Process raw ECG data into QRS metrics\n",
    "            #print(f'start nk.ecg_process for timestamp {timestamp}')\n",
    "            filtered_ecg_ecgonly_signals, _ = nk.ecg_process(filtered_ecg_ecgonly, sampling_rate=100, method='neurokit')\n",
    "            \n",
    "            # Calculate HRV features\n",
    "            print(f'start nk.hrv for {start_time} until {end_time}')\n",
    "            hrv_baseline = nk.hrv(filtered_ecg_ecgonly_signals['ECG_R_Peaks'], sampling_rate=100, nperseg=256, show=False)\n",
    "\n",
    "            ######### Descriptive statistic calculation\n",
    "\n",
    "            # Compute descriptive statistics for HR [bpm] and HRV [ms]\n",
    "            hr_column = 'HR [bpm]'\n",
    "            hrv_column = 'HRV [ms]'\n",
    "                        \n",
    "            hr_mean = round(filtered_hr[hr_column].mean(), 2)\n",
    "            hr_stdev = round(filtered_hr[hr_column].std(), 2)\n",
    "            hrv_mean = round(filtered_hr[hrv_column].mean(), 2)\n",
    "            hrv_stdev = round(filtered_hr[hrv_column].std(), 2)\n",
    "\n",
    "            # Create a dictionary with the results\n",
    "            stats = {\n",
    "                'hr_mean': hr_mean,\n",
    "                'hr_stdev': hr_stdev,\n",
    "                'hrv_mean': hrv_mean,\n",
    "                'hrv_stdev': hrv_stdev\n",
    "            }\n",
    "\n",
    "            ######### merge and store\n",
    "\n",
    "            stats_df = pd.DataFrame([stats])\n",
    "\n",
    "            # Ensure baseline_ECGfeatures is not None before modifying it\n",
    "            if hrv_baseline is not None:\n",
    "                # Concatenate stats_df and baseline_ECGfeatures, ensuring stats come first\n",
    "                hrv_baseline = pd.concat([stats_df, hrv_baseline], axis=1)\n",
    "            else:\n",
    "                print(f\"hrv_baseline is missing or could not be loaded for p_id {p_id}. Skipping.\")\n",
    "                continue\n",
    "        \n",
    "            # Save the results to a CSV file named after the p_id\n",
    "            \n",
    "            hrv_baseline.to_csv(output_file_path, index=None)\n",
    "            print(f\"{output_file_path} successfully SAVED for {p_id}\")\n",
    "        else:\n",
    "            print(f\"Skipping folder {folder_path} due to missing data files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\00-code_export\n",
      "No file with '_baseline_HRVfeatures.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "No file with 'ratings_wHRV.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "baseline_ECGfeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\00-code_export.\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\03\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_HRVfeatures.csv\n",
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratings_wHRV.csv\n",
      "C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratings_HRV_baselinecorrected.csv successfully saved for 03\n",
      "Processing folder: C:\\Users\\BootMR\\Documents\\data_export\\04\n",
      "No file with '_baseline_HRVfeatures.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "No file with 'ratings_wHRV.csv' in its name found in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n",
      "baseline_ECGfeatures missing or empty in folder C:\\Users\\BootMR\\Documents\\data_export\\04.\n"
     ]
    }
   ],
   "source": [
    "########### need this one\n",
    "\n",
    "## adapt and re use this script: \n",
    "\n",
    "skip_p_ids = [f\"{i:02}\" for i in range(1)]\n",
    "\n",
    "\n",
    "# Iterate through each subfolder in the root folder\n",
    "for p_id in os.listdir(parent_dir):\n",
    "    folder_path = os.path.join(parent_dir, p_id)\n",
    "    \n",
    "    if p_id in skip_p_ids:\n",
    "        print(f\"Skipping folder as instructed: {folder_path} (p_id {p_id})\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        \n",
    "        print(f\"Processing folder: {folder_path}\")\n",
    "        \n",
    "        # Initialize an empty DataFrame to store the results for the current p_id\n",
    "        button_features = pd.DataFrame()\n",
    "        \n",
    "        # Load ECG and buttons data\n",
    "        baseline_ECGfeatures = load_file_into_dataframe(folder_path, '_baseline_HRVfeatures.csv', '.csv', ',')      \n",
    "        ratings_wHRV = load_file_into_dataframe(folder_path, 'ratings_wHRV.csv', '.csv', ',')\n",
    "\n",
    "        if baseline_ECGfeatures is None or baseline_ECGfeatures.empty:\n",
    "            print(f\"baseline_ECGfeatures missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if ratings_wHRV is None or ratings_wHRV.empty:\n",
    "            print(f\"ratings_wHRV missing or empty in folder {folder_path}.\")\n",
    "            continue\n",
    "        \n",
    "        if baseline_ECGfeatures is not None and ratings_wHRV is not None:\n",
    "            # Convert 'timestamp' column to datetime format\n",
    "            ratings_wHRV['timestamp_button'] = pd.to_datetime(ratings_wHRV['timestamp_button'])\n",
    "\n",
    "            # Ensure all columns in baseline_ECGfeatures exist in ratings_wHRV\n",
    "            for col in baseline_ECGfeatures.columns:\n",
    "                if col not in ratings_wHRV.columns:\n",
    "                    ratings_wHRV[col] = float('nan')  # Fill missing columns with NaN\n",
    "\n",
    "            # Select only the HRV feature columns (excluding non-HRV columns)\n",
    "            hrv_columns = baseline_ECGfeatures.columns\n",
    "\n",
    "            # Subtract baseline features from button ECG features\n",
    "            ratings_wHRV[hrv_columns] = ratings_wHRV[hrv_columns] - baseline_ECGfeatures.iloc[0]\n",
    "\n",
    "            # Z-standardize each HRV feature\n",
    "            #ratings_wHRV[hrv_columns] = (ratings_wHRV[hrv_columns] - ratings_wHRV[hrv_columns].mean()) / ratings_wHRV[hrv_columns].std()\n",
    "\n",
    "            # Save the concatenated DataFrame to CSV\n",
    "            output_file_path = os.path.join(folder_path, f\"{p_id}_ratings_HRV_baselinecorrected.csv\")\n",
    "            ratings_wHRV.to_csv(output_file_path, index=None)\n",
    "            print(f\"{output_file_path} successfully saved for {p_id}\")\n",
    "        else:\n",
    "            print(f\"Skipping folder {folder_path} due to missing data files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge baselines into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_baseline_HRVfeatures.csv\n",
      "All files merged into: C:\\Users\\BootMR\\Documents\\data_export\\all_baselineHRVfeatures.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate through each subfolder in the parent directory\n",
    "for subdir, dirs, files in os.walk(parent_dir):\n",
    "    # Check each file in the subfolder\n",
    "    for file in files:\n",
    "        if 'baseline_HRVfeatures' in file:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            # Load the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "if dfs:\n",
    "    all_baseline_HRVfeatures = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(parent_dir, 'all_baselineHRVfeatures.csv')\n",
    "    \n",
    "    # Save the concatenated DataFrame to CSV\n",
    "    all_baseline_HRVfeatures.to_csv(output_file_path, index=False)\n",
    "    print(f\"All files merged into: {output_file_path}\")\n",
    "else:\n",
    "    print(\"No files found with 'baseline_HRVfeatures' in the filename.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge ratings_wHRV into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratings_wHRV.csv, Rows: 8\n",
      "Saved merged DataFrame to: C:\\Users\\BootMR\\Documents\\data_export\\all_ratingswHRV.csv, Total Rows: 8\n"
     ]
    }
   ],
   "source": [
    "## merge all individual files into 1 large\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all subfolders\n",
    "for subdir, _, files in os.walk(parent_dir):\n",
    "    # Skip the root directory itself\n",
    "    if subdir == parent_dir:\n",
    "        continue\n",
    "    \n",
    "    # Extract the subfolder name\n",
    "    subfolder_name = os.path.basename(subdir)\n",
    "    \n",
    "    # Check for files containing \"FlirtNkFeatures\" in the current subfolder\n",
    "    for file in files:\n",
    "        if \"ratings_wHRV\" in file:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                # Read the file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Add the subfolder name as a new column\n",
    "                df['p_id'] = subfolder_name\n",
    "                \n",
    "                # Reorder the columns\n",
    "                cols = df.columns.tolist()\n",
    "                reordered_cols = ['rating', 'timestamp_button', 'p_id'] + [col for col in cols if col not in ['rating', 'timestamp_button', 'p_id']]\n",
    "                df = df[reordered_cols]\n",
    "                \n",
    "                # Append the DataFrame to the list\n",
    "                dataframes.append(df)\n",
    "                print(f\"Loaded file: {file_path}, Rows: {len(df)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if dataframes:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    output_file_path = os.path.join(parent_dir, \"all_ratingswHRV.csv\")\n",
    "    merged_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved merged DataFrame to: {output_file_path}, Total Rows: {len(merged_df)}\")\n",
    "else:\n",
    "    print(\"No files with 'FlirtNkFeatures' found in any subfolder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge ratings_HRV_corrected into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: C:\\Users\\BootMR\\Documents\\data_export\\03\\03_ratings_HRV_baselinecorrected.csv, Rows: 8\n",
      "Saved merged DataFrame to: C:\\Users\\BootMR\\Documents\\data_export\\all_ratingswHRV_corrected.csv, Total Rows: 8\n"
     ]
    }
   ],
   "source": [
    "## merge all individual files into 1 large\n",
    "\n",
    "# Initialize a list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all subfolders\n",
    "for subdir, _, files in os.walk(parent_dir):\n",
    "    # Skip the root directory itself\n",
    "    if subdir == parent_dir:\n",
    "        continue\n",
    "    \n",
    "    # Extract the subfolder name\n",
    "    subfolder_name = os.path.basename(subdir)\n",
    "    \n",
    "    # Check for files containing \"FlirtNkFeatures\" in the current subfolder\n",
    "    for file in files:\n",
    "        if \"ratings_HRV_baselinecorrected\" in file:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                # Read the file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                # Add the subfolder name as a new column\n",
    "                df['p_id'] = subfolder_name\n",
    "                \n",
    "                # Reorder the columns\n",
    "                cols = df.columns.tolist()\n",
    "                reordered_cols = ['rating', 'timestamp_button', 'p_id'] + [col for col in cols if col not in ['rating', 'timestamp_button', 'p_id']]\n",
    "                df = df[reordered_cols]\n",
    "                \n",
    "                # Append the DataFrame to the list\n",
    "                dataframes.append(df)\n",
    "                print(f\"Loaded file: {file_path}, Rows: {len(df)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if dataframes:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    output_file_path = os.path.join(parent_dir, \"all_ratingswHRV_corrected.csv\")\n",
    "    merged_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Saved merged DataFrame to: {output_file_path}, Total Rows: {len(merged_df)}\")\n",
    "else:\n",
    "    print(\"No files with 'FlirtNkFeatures' found in any subfolder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
